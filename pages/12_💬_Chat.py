import streamlit as st
from ollama_api import ollama_generator, get_available_models  # å¯¼å…¥ Ollama API å‡½æ•°
from hunyuan_api import hunyuan_generator  # å¯¼å…¥æ··å…ƒå¤§æ¨¡å‹ API å‡½æ•°

st.set_page_config(
    page_title="chat",
    page_icon="ğŸ’¬",
)
st.sidebar.header("ä¸ AI èŠå¤©")
st.header("èŠå¤©")
if "selected_model" not in st.session_state:
    st.session_state.selected_model = ""
if "selected_platform" not in st.session_state:
    st.session_state.selected_platform = "æ··å…ƒ"  # é»˜è®¤å¹³å°ä¸ºæ··å…ƒ
if "messages" not in st.session_state:
    st.session_state.messages = []

# é€‰æ‹©ä½¿ç”¨çš„å¹³å°ï¼ˆæ··å…ƒ æˆ– Ollamaï¼‰
st.session_state.selected_platform = st.selectbox(
    "è¯·é€‰æ‹©å¹³å°ï¼š",
    ["æ··å…ƒ", "Ollama"],
    index=0,  # é»˜è®¤é€‰æ‹©æ··å…ƒ
)

# æ ¹æ®é€‰æ‹©çš„å¹³å°è·å–ç›¸åº”çš„æ¨¡å‹åˆ—è¡¨
if st.session_state.selected_platform == "Ollama":
    st.session_state.selected_model = st.selectbox(
        "è¯·é€‰æ‹© Ollama æ¨¡å‹ï¼š", get_available_models()
    )
else:
    st.session_state.selected_model = st.selectbox(
        "è¯·é€‰æ‹©æ··å…ƒæ¨¡å‹ï¼š",
        [
            "hunyuan-lite",
            "hunyuan-standard",
            "hunyuan-standard-256K",
            "hunyuan-pro",
            "hunyuan-code",
            "hunyuan-role",
            "hunyuan-functioncall",
            "hunyuan-vision",
        ],
    )

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# æ¥æ”¶ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨ï¼Ÿ"):
    # ä¿å­˜ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ ¹æ®é€‰å®šçš„å¹³å°ç”Ÿæˆæ¨¡å‹çš„å›å¤
    with st.chat_message("assistant"):
        if st.session_state.selected_platform == "Ollama":
            response = st.write_stream(
                ollama_generator(
                    st.session_state.selected_model, st.session_state.messages
                )
            )
        else:
            response = st.write_stream(
                hunyuan_generator(
                    st.session_state.selected_model, st.session_state.messages
                )
            )

    st.session_state.messages.append({"role": "assistant", "content": response})

